{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69384376",
   "metadata": {},
   "source": [
    "# EfficientNet-B4 Processed Merged Gamma with extra cross entropy Weight to handle imbalance\n",
    "\n",
    "\n",
    "Here we run experiment with ODIR-2019 Gamma enhanced Processed images and additional training images from Ocular Diseases DataSet\n",
    "except for Normal which we leave the ODIR-2019 original images as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133271bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './ODIR-2019/YOLO/processed_512g_merged'  # Your dataset path\n",
    "model_name = 'efficientnet-b4'\n",
    "saved_model_name = 'efficientnet-b4-odir-2019-pmgw.pth'\n",
    "wandb_project = \"odir-2019\"\n",
    "wandb_run_name = 'efficientnet-b4_pmgw'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8f123",
   "metadata": {},
   "source": [
    "The following codes are generic or the same across experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1d01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install efficientnet-pytorch wandb torch torchvision scikit-learn seaborn tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492a99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from efficient_net import EfficientNetTrainer, ODIRFolderDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25612758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GPU (CUDA)\n"
     ]
    }
   ],
   "source": [
    "from util import get_train_device\n",
    "\n",
    "device_for_training = get_train_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4336fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9478 images in train split across 8 classes\n",
      "\n",
      "Class distribution in train split:\n",
      "  normal: 2252 samples (23.8%)\n",
      "  diabetes: 2790 samples (29.4%)\n",
      "  glaucoma: 1574 samples (16.6%)\n",
      "  cataract: 724 samples (7.6%)\n",
      "  ageing: 724 samples (7.6%)\n",
      "  hypertension: 394 samples (4.2%)\n",
      "  myopia: 475 samples (5.0%)\n",
      "  other: 545 samples (5.8%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5260879218472468,\n",
       " 0.4246415770609319,\n",
       " 0.752700127064803,\n",
       " 1.6363950276243093,\n",
       " 1.6363950276243093,\n",
       " 3.0069796954314723,\n",
       " 2.4942105263157894,\n",
       " 2.1738532110091744]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate weighted loss result\n",
    "train=ODIRFolderDataset(\n",
    "            root_dir=data_dir,\n",
    "            split='train',\n",
    "            image_size=512\n",
    "        )\n",
    "train.get_class_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898685cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraymond-samalo\u001b[0m (\u001b[33msamalo\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/wandb/run-20260224_103610-nt9p0740</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/samalo/odir-2019/runs/nt9p0740' target=\"_blank\">efficientnet-b4_pmg</a></strong> to <a href='https://wandb.ai/samalo/odir-2019' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/samalo/odir-2019' target=\"_blank\">https://wandb.ai/samalo/odir-2019</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/samalo/odir-2019/runs/nt9p0740' target=\"_blank\">https://wandb.ai/samalo/odir-2019/runs/nt9p0740</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading efficientnet-b4 with 8 classes...\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loading datasets from ./ODIR-2019/YOLO/processed_512g_merged...\n",
      "Found 9478 images in train split across 8 classes\n",
      "\n",
      "Class distribution in train split:\n",
      "  normal: 2252 samples (23.8%)\n",
      "  diabetes: 2790 samples (29.4%)\n",
      "  glaucoma: 1574 samples (16.6%)\n",
      "  cataract: 724 samples (7.6%)\n",
      "  ageing: 724 samples (7.6%)\n",
      "  hypertension: 394 samples (4.2%)\n",
      "  myopia: 475 samples (5.0%)\n",
      "  other: 545 samples (5.8%)\n",
      "Found 627 images in val split across 8 classes\n",
      "\n",
      "Class distribution in val split:\n",
      "  normal: 282 samples (45.0%)\n",
      "  diabetes: 160 samples (25.5%)\n",
      "  glaucoma: 28 samples (4.5%)\n",
      "  cataract: 26 samples (4.1%)\n",
      "  ageing: 27 samples (4.3%)\n",
      "  hypertension: 13 samples (2.1%)\n",
      "  myopia: 23 samples (3.7%)\n",
      "  other: 68 samples (10.8%)\n",
      "Found 627 images in test split across 8 classes\n",
      "\n",
      "Class distribution in test split:\n",
      "  normal: 282 samples (45.0%)\n",
      "  diabetes: 160 samples (25.5%)\n",
      "  glaucoma: 28 samples (4.5%)\n",
      "  cataract: 27 samples (4.3%)\n",
      "  ageing: 26 samples (4.1%)\n",
      "  hypertension: 13 samples (2.1%)\n",
      "  myopia: 23 samples (3.7%)\n",
      "  other: 68 samples (10.8%)\n",
      "\n",
      "ðŸ“Š Dataset Statistics:\n",
      "   Train samples: 9478\n",
      "   Val samples:   627\n",
      "   Test samples:  627\n",
      "   Image size:    512\n",
      "   Batch size:    16\n",
      "use_weight for cross entropy loss training [0.5260879218472468, 0.4246415770609319, 0.752700127064803, 1.6363950276243093, 1.6363950276243093, 3.0069796954314723, 2.4942105263157894, 2.1738532110091744]\n",
      "\n",
      "============================================================\n",
      "Epoch 1/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   0%|          | 0/592 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "config = {\n",
    "    'data_dir': data_dir,\n",
    "    'model_name': model_name,\n",
    "    'num_classes': 8,\n",
    "    'image_size': 512,\n",
    "    'batch_size': 16,  # Smaller for Jupyter\n",
    "    'epochs': 30,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'optimizer': 'adamw',\n",
    "    'scheduler': 'cosine',\n",
    "    'fine_tune': True,\n",
    "    'unfreeze_blocks': 3,\n",
    "    'label_smoothing': 0.1,\n",
    "    'num_workers': 2,  # Lower for Jupyter\n",
    "    'use_amp': True,\n",
    "    'seed': 42,\n",
    "    'use_weight': True  # use balanced weight with extra weight for hypertension\n",
    "}\n",
    "wandb.init(project=wandb_project, name=wandb_run_name, config=config)\n",
    "trainer = EfficientNetTrainer(config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13229db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6: Test\n",
    "test_loss, test_acc, test_f1 = trainer.test()\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test F1: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "final_model_path = os.path.join('ODIR-2019/results/', saved_model_name)\n",
    "trainer.save_model(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6797722",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
