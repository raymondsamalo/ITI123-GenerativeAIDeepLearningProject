{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gradio torch efficientnet-pytorch plotly pillow matplotlib ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from efficient_net import EfficientNetTrainer\n",
    "from preprocessor import ODIRImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': 'efficientnet-b4',\n",
    "    'num_classes': 8,\n",
    "    'image_size': 512,\n",
    "}\n",
    "MODEL_PATH = \"ODIR-2019/results/efficientnet-b4-odir-2019-pmg.pth\"  # Change this to your model path\n",
    "trainer = EfficientNetTrainer(config)\n",
    "trainer.load_model(path=MODEL_PATH)\n",
    "processor = ODIRImageProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d4487a",
   "metadata": {},
   "source": [
    "## SANITY CHECK\n",
    "Here we check whether our model is able to predict correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict_single_image_path(image_path=\"ODIR-2019/YOLO/processed_512g_merged/test/diabetes/26_left.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c021a",
   "metadata": {},
   "source": [
    "Check for image that has not been processed, using our preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict_single_image_path(image_path=\"ODIR-2019/YOLO/preprocessed/test/diabetes/26_left.jpg\", \n",
    "                             preprocessor=processor.load_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# Let's assume your updated function now takes a NumPy array:\n",
    "ODIR_CLASS_DESCRIPTIONS = {\n",
    "    'normal': 'Healthy fundus with no apparent pathologies',\n",
    "    'diabetes': 'Diabetic Retinopathy - presence of microaneurysms, hemorrhages, hard exudates, cotton wool spots, or neovascularization',\n",
    "    'glaucoma': 'Glaucoma - optic nerve damage with increased cup-to-disc ratio, retinal nerve fiber layer defects',\n",
    "    'cataract': 'Cataract - lens opacity visible through fundus image',\n",
    "    'ageing': 'Age-related Macular Degeneration - drusen, pigmentary changes, geographic atrophy, or neovascularization in macular region',\n",
    "    'hypertension': 'Hypertensive Retinopathy - arteriovenous nicking, copper/silver wiring, flame-shaped hemorrhages',\n",
    "    'myopia': 'Pathological Myopia - tessellated fundus, peripapillary atrophy, posterior staphyloma',\n",
    "    'other': 'Other retinal conditions including vein occlusion, retinal detachment, tumors, etc.'\n",
    "}\n",
    "\n",
    "def diagnosis_wrapper(input_array):\n",
    "    if input_array is None:\n",
    "        # Return empty/default values to the outputs to prevent a crash\n",
    "        return None, {}, \"No image provided. Please upload a scan.\"\n",
    "    # 1. Handle Color Space\n",
    "    # Gradio provides RGB. If your model/OpenCV logic expects BGR:\n",
    "    # input_bgr = cv2.cvtColor(input_array, cv2.COLOR_RGB2BGR)\n",
    "    img_bgr=cv2.cvtColor(input_array, cv2.COLOR_RGB2BGR)\n",
    "    img_bgr=processor.preprocess_image(img_bgr)\n",
    "    img_rgb=cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(img_rgb)\n",
    "    # 2. Run your prediction on the array\n",
    "    # (Update your predict function to accept the array instead of a path)\n",
    "    results = trainer.predict_single_image(img)\n",
    "    \n",
    "    # 3. Format results for Gradio Label\n",
    "    confidences = {label: float(conf) for label, conf in results['predictions']}\n",
    "    predicted_class = results[\"predicted_class\"]\n",
    "    predicted_conf = round(results[\"confidence\"]*100)\n",
    "    comment = ODIR_CLASS_DESCRIPTIONS.get(predicted_class,\"\")\n",
    "    summary=f\"The model predict with {predicted_conf}% confidence that the eye is likely {predicted_class}\\n{comment}\"\n",
    "    # 4. Return the image array itself and the labels\n",
    "    return img_rgb, confidences, summary\n",
    "\n",
    "# Define the Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## üëÅÔ∏è Rapid Eye Analysis\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        # INPUT: Set type=\"numpy\" to pass the actual pixel array\n",
    "        with gr.Column():\n",
    "            img_input = gr.Image(type=\"numpy\", label=\"Input Image\", width=512, height=512)\n",
    "        with gr.Column():\n",
    "            summary = gr.Textbox(label=\"Summary\")    \n",
    "            label_output = gr.Label(num_top_classes=5)\n",
    "        with gr.Column():\n",
    "            img_output = gr.Image(label=\"Processed Image\", width=512, height=512)\n",
    "\n",
    "    # Link the input change directly to the function for real-time feel\n",
    "    img_input.change(\n",
    "        fn=diagnosis_wrapper, \n",
    "        inputs=img_input, \n",
    "        outputs=[img_output, label_output, summary]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
