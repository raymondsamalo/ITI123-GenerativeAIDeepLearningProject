{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61b066f",
   "metadata": {},
   "source": [
    "# yolo-preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb0c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ultralytics wandb torch yaml scikit-learn seaborn tqdm matplotlib cv2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1777c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "# from yolo import ODIRYOLOTrainer\n",
    "from yolo_trainer import ODIRYOLOTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509f7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"yolo11n-cls-preprocessed\"\n",
    "model_version = 'yolo11n-cls'\n",
    "data_dir = \"./ODIR-2019/YOLO/preprocessed\"\n",
    "project_name = \"odir-2019-yolo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c21ac3",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97a5c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model version: yolo11n-cls\n",
      "Number of classes: 8\n",
      "Classes: ['normal', 'diabetes', 'glaucoma', 'cataract', 'ageing', 'hypertension', 'myopia', 'other']\n",
      "W&B logging: True\n",
      "Run directory: yolo-runs\n",
      "\n",
      "==================================================\n",
      "Training yolo11n-cls on ODIR-2019\n",
      "Image size: 512x512\n",
      "==================================================\n",
      "Loading model: yolo11n-cls\n",
      "Data folder: ODIR-2019/YOLO/preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraymond-samalo\u001b[0m (\u001b[33msamalo\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/wandb/run-20260205_154524-2cwfx092</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">yolo11n-cls-preprocessed</a></strong> to <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B integration enabled for training\n",
      "\n",
      "Starting training...\n",
      "New https://pypi.org/project/ultralytics/8.4.11 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2050, 3769MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=ODIR-2019/YOLO/preprocessed, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n-cls_imgsz512_20260205_154523, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo-runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/yolo-runs/yolo11n-cls_imgsz512_20260205_154523, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/train... found 5014 images in 8 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/val... found 627 images in 8 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/test... found 627 images in 8 classes âœ… \n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    340488  ultralytics.nn.modules.head.Classify         [256, 8]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,541,352 parameters, 1,541,352 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=512 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 2050) 3.68G total, 0.09G reserved, 0.05G allocated, 3.54G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     1541352       2.081         0.157         11.31         965.5        (1, 3, 512, 512)                  (1, 8)\n",
      "     1541352       4.162         0.210          6.36         613.8        (2, 3, 512, 512)                  (2, 8)\n",
      "     1541352       8.323         0.310         7.682         612.1        (4, 3, 512, 512)                  (4, 8)\n",
      "     1541352       16.65         0.570         12.79           600        (8, 3, 512, 512)                  (8, 8)\n",
      "     1541352       33.29         1.053         26.08         614.7       (16, 3, 512, 512)                 (16, 8)\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 31 for CUDA:0 2.10G/3.68G (57%) âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3207.3Â±1087.2 MB/s, size: 56.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/train... 5014 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5014/5014 5.1Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1777.2Â±1037.7 MB/s, size: 55.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/val... 627 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 627/627 896.3Kit/s 0.0s\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.000484375), 40 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/yolo-runs/yolo11n-cls_imgsz512_20260205_154523\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       1/30         2G      1.443         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 4.6it/s 34.9s0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 5.7it/s 1.9s0.1s\n",
      "                   all      0.612      0.981\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/30      1.57G       1.16         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.2it/s 31.3s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.1it/s 1.4s0.1s\n",
      "                   all      0.604      0.979\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/30      1.58G      1.118         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.2it/s 1.3s0.1s\n",
      "                   all       0.59      0.984\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/30      1.58G      1.071         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.5s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.1it/s 1.4s0.1s\n",
      "                   all      0.619      0.976\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/30      1.58G     0.9989         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.3s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.671       0.99\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/30      1.58G     0.9984         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.4s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.1it/s 1.4s0.1s\n",
      "                   all      0.675      0.986\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/30      1.58G     0.9408         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.4s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.0it/s 1.4s0.1s\n",
      "                   all      0.665      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/30      1.58G      0.897         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.5s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.675       0.99\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/30      1.58G     0.9045         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.1it/s 31.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.668      0.994\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/30      1.59G     0.8737         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.2s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.2it/s 1.3s0.1s\n",
      "                   all       0.67      0.995\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/30      1.59G     0.8394         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.687      0.987\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/30      1.59G     0.8218         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.4s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.2it/s 1.3s0.1s\n",
      "                   all      0.699      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/30      1.59G     0.7978         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.1it/s 31.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.1it/s 1.4s0.1s\n",
      "                   all      0.707       0.99\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/30      1.59G     0.7789         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.1it/s 32.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.705      0.994\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/30       1.6G     0.7658         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.4s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.2it/s 1.3s0.1s\n",
      "                   all      0.686      0.994\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      16/30       1.6G     0.7461         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.1it/s 31.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.2it/s 1.3s0.1s\n",
      "                   all       0.71      0.986\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      17/30       1.6G     0.7095         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.0it/s 1.4s0.1s\n",
      "                   all      0.668      0.994\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      18/30       1.6G     0.6959         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.1it/s 32.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.1it/s 1.4s0.1s\n",
      "                   all      0.716       0.99\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      19/30       1.6G      0.664         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.711      0.987\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      20/30       1.6G     0.6485         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.707      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      21/30       1.6G     0.6338         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 4.7it/s 34.1s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.4it/s 1.3s0.1s\n",
      "                   all      0.711       0.99\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      22/30       1.6G     0.5977         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.4s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.695      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      23/30       1.6G     0.5892         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 4.9it/s 33.4s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.716      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      24/30       1.6G     0.5676         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 4.9it/s 33.3s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.2it/s 1.3s0.1s\n",
      "                   all      0.707      0.994\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      25/30       1.6G     0.5465         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 4.9it/s 33.0s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.4it/s 1.3s0.1s\n",
      "                   all      0.699       0.99\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      26/30       1.6G     0.5398         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 4.8it/s 33.7s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.4it/s 1.3s0.1s\n",
      "                   all      0.719      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      27/30       1.6G     0.5006         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 5.0it/s 32.6s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.4it/s 1.3s0.1s\n",
      "                   all      0.729       0.99\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      28/30       1.6G     0.4823         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 4.9it/s 32.8s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all      0.726      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      29/30       1.6G     0.4706         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 4.9it/s 33.3s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.4it/s 1.3s0.1s\n",
      "                   all      0.715      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      30/30       1.6G     0.4639         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 162/162 4.9it/s 32.9s0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 8.3it/s 1.3s0.1s\n",
      "                   all       0.71      0.992\n",
      "\n",
      "30 epochs completed in 0.284 hours.\n",
      "Optimizer stripped from /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/yolo-runs/yolo11n-cls_imgsz512_20260205_154523/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/yolo-runs/yolo11n-cls_imgsz512_20260205_154523/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/yolo-runs/yolo11n-cls_imgsz512_20260205_154523/weights/best.pt...\n",
      "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2050, 3769MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,536,272 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/train... found 5014 images in 8 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/val... found 627 images in 8 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/test... found 627 images in 8 classes âœ… \n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 5.6it/s 2.0s0.2s\n",
      "                   all      0.729       0.99\n",
      "Speed: 0.7ms preprocess, 1.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/yolo-runs/yolo11n-cls_imgsz512_20260205_154523\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–ƒâ–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>lr/pg1</td><td>â–ƒâ–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>lr/pg2</td><td>â–ƒâ–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>metrics/accuracy_top1</td><td>â–‚â–‚â–â–‚â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–†â–‡â–…â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–‡â–‡</td></tr><tr><td>metrics/accuracy_top5</td><td>â–ƒâ–‚â–„â–â–†â–…â–†â–†â–‡â–ˆâ–…â–‡â–†â–‡â–‡â–…â–‡â–†â–…â–‡â–†â–†â–†â–‡â–†â–‡â–†â–‡â–‡â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–†â–†â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>val/loss</td><td>â–ˆâ–‡â–ˆâ–‡â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–â–‚â–â–ƒâ–â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/accuracy_top1</td><td>0.70973</td></tr><tr><td>metrics/accuracy_top5</td><td>0.99203</td></tr><tr><td>model/GFLOPs</td><td>3.261</td></tr><tr><td>model/parameters</td><td>1541352</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>2.37</td></tr><tr><td>train/loss</td><td>0.4639</td></tr><tr><td>val/loss</td><td>0.91238</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-preprocessed</strong> at: <a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092</a><br> View project at: <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo</a><br>Synced 5 W&B file(s), 15 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_154524-2cwfx092/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2050, 3769MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,536,272 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/train... found 5014 images in 8 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/val... found 627 images in 8 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/test... found 627 images in 8 classes âœ… \n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2625.8Â±931.0 MB/s, size: 55.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/ODIR-2019/YOLO/preprocessed/val... 627 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 627/627 1.3Mit/s 0.0s0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 40/40 11.3it/s 3.5s0.0s\n",
      "                   all      0.729       0.99\n",
      "Speed: 0.9ms preprocess, 3.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/runs/classify/val2\u001b[0m\n",
      "\n",
      "Final validation metrics: ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x709c36ae6e40>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.859649121761322\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.7288676500320435, 'metrics/accuracy_top5': 0.9904305934906006, 'fitness': 0.859649121761322}\n",
      "save_dir: PosixPath('/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/runs/classify/val2')\n",
      "speed: {'preprocess': 0.855045511961567, 'inference': 3.1399002966406586, 'loss': 0.0004341531096947598, 'postprocess': 0.0028385709715382144}\n",
      "task: 'classify'\n",
      "top1: 0.7288676500320435\n",
      "top5: 0.9904305934906006\n",
      "W&B run finished\n",
      "\n",
      "Training completed in 1039.38 seconds\n",
      "Training summary saved to: yolo-runs/yolo11n-cls_imgsz512_20260205_154523/training_summary.txt\n",
      "No training history to plot\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/wandb/run-20260205_160251-2cwfx092</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">yolo11n-cls-preprocessed</a></strong> to <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>â–</td></tr><tr><td>best_accuracy</td><td>â–</td></tr><tr><td>best_epoch</td><td>â–</td></tr><tr><td>best_f1</td><td>â–</td></tr><tr><td>best_precision</td><td>â–</td></tr><tr><td>best_recall</td><td>â–</td></tr><tr><td>image_size</td><td>â–</td></tr><tr><td>training_time</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>-1</td></tr><tr><td>best_accuracy</td><td>0.72887</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_f1</td><td>0</td></tr><tr><td>best_precision</td><td>0</td></tr><tr><td>best_recall</td><td>0</td></tr><tr><td>image_size</td><td>512</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>+14</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-preprocessed</strong> at: <a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092</a><br> View project at: <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_160251-2cwfx092/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B run finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x709c79e1b4d0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.859649121761322\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.7288676500320435, 'metrics/accuracy_top5': 0.9904305934906006, 'fitness': 0.859649121761322}\n",
       "save_dir: PosixPath('/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/yolo-runs/yolo11n-cls_imgsz512_20260205_154523')\n",
       "speed: {'preprocess': 0.708353537481055, 'inference': 1.528243234449917, 'loss': 0.0019974912317826943, 'postprocess': 0.0027079697023860683}\n",
       "task: 'classify'\n",
       "top1: 0.7288676500320435\n",
       "top5: 0.9904305934906006"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ODIRYOLOTrainer(model_version=model_version, use_wandb=True, wandb_project_name=project_name, wandb_run_name=run_name)\n",
    "trainer.train_from_folder(data_folder=data_dir, epochs=30, batch_size=-1, imgsz=512, patience=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dadd731",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cea0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on validation set...\n",
      "Found 627 images in validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 627/627 [00:05<00:00, 108.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS for VALIDATION SET\n",
      "==================================================\n",
      "Total images: 627\n",
      "Accuracy: 0.0702\n",
      "F1-Score (Micro): 0.0702\n",
      "F1-Score (Macro): 0.0800\n",
      "F1-Score (Weighted): 0.0769\n",
      "\n",
      "Average Inference Time: 0.0090 seconds\n",
      "Inference Time Std: 0.0021 seconds\n",
      "FPS: 111.11\n",
      "\n",
      "Per-class F1 Scores:\n",
      "  normal         : 0.0133\n",
      "  diabetes       : 0.0205\n",
      "  glaucoma       : 0.0000\n",
      "  cataract       : 0.0000\n",
      "  ageing         : 0.0000\n",
      "  hypertension   : 0.0000\n",
      "  myopia         : 0.0000\n",
      "  other          : 0.6061\n",
      "Confusion matrix saved to: yolo-runs/confusion_matrices/confusion_matrix_yolo11n-cls_validation_512_20260205_160300.png\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/wandb/run-20260205_160302-2cwfx092</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">yolo11n-cls-preprocessed</a></strong> to <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>-1</td></tr><tr><td>best_accuracy</td><td>0.72887</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_f1</td><td>0</td></tr><tr><td>best_precision</td><td>0</td></tr><tr><td>best_recall</td><td>0</td></tr><tr><td>image_size</td><td>512</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>+14</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-preprocessed</strong> at: <a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092</a><br> View project at: <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo</a><br>Synced 4 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_160302-2cwfx092/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B run finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'split': 'validation',\n",
       " 'accuracy': np.float64(0.07017543859649122),\n",
       " 'f1_micro': 0.07017543859649122,\n",
       " 'f1_macro': 0.07998280788978464,\n",
       " 'f1_weighted': 0.07694047974453003,\n",
       " 'f1_per_class': {'normal': np.float64(0.013289036544850499),\n",
       "  'diabetes': np.float64(0.020512820512820513),\n",
       "  'glaucoma': np.float64(0.0),\n",
       "  'cataract': np.float64(0.0),\n",
       "  'ageing': np.float64(0.0),\n",
       "  'hypertension': np.float64(0.0),\n",
       "  'myopia': np.float64(0.0),\n",
       "  'other': np.float64(0.6060606060606061)},\n",
       " 'avg_inference_time': np.float64(0.009000481220713834),\n",
       " 'std_inference_time': np.float64(0.002110532015527896),\n",
       " 'fps': np.float64(111.10517043228599),\n",
       " 'image_size': 512,\n",
       " 'total_images': 627,\n",
       " 'classification_report': {'normal': {'precision': 0.10526315789473684,\n",
       "   'recall': 0.0070921985815602835,\n",
       "   'f1-score': 0.013289036544850499,\n",
       "   'support': 282.0},\n",
       "  'diabetes': {'precision': 0.05714285714285714,\n",
       "   'recall': 0.0125,\n",
       "   'f1-score': 0.020512820512820513,\n",
       "   'support': 160.0},\n",
       "  'glaucoma': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 28.0},\n",
       "  'cataract': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 26.0},\n",
       "  'ageing': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 27.0},\n",
       "  'hypertension': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 13.0},\n",
       "  'myopia': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 23.0},\n",
       "  'other': {'precision': 0.625,\n",
       "   'recall': 0.5882352941176471,\n",
       "   'f1-score': 0.6060606060606061,\n",
       "   'support': 68.0},\n",
       "  'accuracy': 0.07017543859649122,\n",
       "  'macro avg': {'precision': 0.09842575187969925,\n",
       "   'recall': 0.07597843658740092,\n",
       "   'f1-score': 0.07998280788978464,\n",
       "   'support': 627.0},\n",
       "  'weighted avg': {'precision': 0.12970824189660754,\n",
       "   'recall': 0.07017543859649122,\n",
       "   'f1-score': 0.07694047974453003,\n",
       "   'support': 627.0}},\n",
       " 'confusion_matrix': array([[  2,   3,  14,  11,   1,   5, 234,  12],\n",
       "        [  0,   2, 113,   0,   5,   0,  32,   8],\n",
       "        [  0,   1,   0,  11,   0,   0,  16,   0],\n",
       "        [  0,  22,   0,   0,   0,   0,   3,   1],\n",
       "        [ 14,   0,   3,   1,   0,   1,   7,   1],\n",
       "        [  0,   0,   5,   0,   2,   0,   5,   1],\n",
       "        [  0,   0,   1,   0,   0,  21,   0,   1],\n",
       "        [  3,   7,   7,   0,   0,   0,  11,  40]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate_on_validation(data_folder=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3473f5ed",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d412804f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n",
      "Found 627 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 627/627 [00:06<00:00, 95.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS for TEST SET\n",
      "==================================================\n",
      "Total images: 627\n",
      "Accuracy: 0.0622\n",
      "F1-Score (Micro): 0.0622\n",
      "F1-Score (Macro): 0.0725\n",
      "F1-Score (Weighted): 0.0670\n",
      "\n",
      "Average Inference Time: 0.0103 seconds\n",
      "Inference Time Std: 0.0045 seconds\n",
      "FPS: 97.51\n",
      "\n",
      "Per-class F1 Scores:\n",
      "  normal         : 0.0195\n",
      "  diabetes       : 0.0000\n",
      "  glaucoma       : 0.0347\n",
      "  cataract       : 0.0000\n",
      "  ageing         : 0.0000\n",
      "  hypertension   : 0.0000\n",
      "  myopia         : 0.0059\n",
      "  other          : 0.5203\n",
      "Confusion matrix saved to: yolo-runs/confusion_matrices/confusion_matrix_yolo11n-cls_test_512_20260205_160313.png\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ray/Projects/ITI123-GenerativeAIDeepLearningProject/wandb/run-20260205_160315-2cwfx092</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">yolo11n-cls-preprocessed</a></strong> to <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>-1</td></tr><tr><td>best_accuracy</td><td>0.72887</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_f1</td><td>0</td></tr><tr><td>best_precision</td><td>0</td></tr><tr><td>best_recall</td><td>0</td></tr><tr><td>image_size</td><td>512</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>+17</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-preprocessed</strong> at: <a href='https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo/runs/2cwfx092</a><br> View project at: <a href='https://wandb.ai/samalo/odir-2019-yolo' target=\"_blank\">https://wandb.ai/samalo/odir-2019-yolo</a><br>Synced 4 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_160315-2cwfx092/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B run finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'split': 'test',\n",
       " 'accuracy': np.float64(0.06220095693779904),\n",
       " 'f1_micro': 0.06220095693779904,\n",
       " 'f1_macro': 0.0725484385840196,\n",
       " 'f1_weighted': 0.06695759457078132,\n",
       " 'f1_per_class': {'normal': np.float64(0.01948051948051948),\n",
       "  'diabetes': np.float64(0.0),\n",
       "  'glaucoma': np.float64(0.03468208092485549),\n",
       "  'cataract': np.float64(0.0),\n",
       "  'ageing': np.float64(0.0),\n",
       "  'hypertension': np.float64(0.0),\n",
       "  'myopia': np.float64(0.0058997050147492625),\n",
       "  'other': np.float64(0.5203252032520326)},\n",
       " 'avg_inference_time': np.float64(0.010255608642310426),\n",
       " 'std_inference_time': np.float64(0.0044760258845235115),\n",
       " 'fps': np.float64(97.50762093966915),\n",
       " 'image_size': 512,\n",
       " 'total_images': 627,\n",
       " 'classification_report': {'normal': {'precision': 0.11538461538461539,\n",
       "   'recall': 0.010638297872340425,\n",
       "   'f1-score': 0.01948051948051948,\n",
       "   'support': 282.0},\n",
       "  'diabetes': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 160.0},\n",
       "  'glaucoma': {'precision': 0.020689655172413793,\n",
       "   'recall': 0.10714285714285714,\n",
       "   'f1-score': 0.03468208092485549,\n",
       "   'support': 28.0},\n",
       "  'cataract': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 27.0},\n",
       "  'ageing': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 26.0},\n",
       "  'hypertension': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 13.0},\n",
       "  'myopia': {'precision': 0.0031645569620253164,\n",
       "   'recall': 0.043478260869565216,\n",
       "   'f1-score': 0.0058997050147492625,\n",
       "   'support': 23.0},\n",
       "  'other': {'precision': 0.5818181818181818,\n",
       "   'recall': 0.47058823529411764,\n",
       "   'f1-score': 0.5203252032520326,\n",
       "   'support': 68.0},\n",
       "  'accuracy': 0.06220095693779904,\n",
       "  'macro avg': {'precision': 0.09013212616715455,\n",
       "   'recall': 0.07898095639736005,\n",
       "   'f1-score': 0.0725484385840196,\n",
       "   'support': 627.0},\n",
       "  'weighted avg': {'precision': 0.11603539562528242,\n",
       "   'recall': 0.06220095693779904,\n",
       "   'f1-score': 0.06695759457078132,\n",
       "   'support': 627.0}},\n",
       " 'confusion_matrix': array([[  3,   5,  25,   9,   0,   1, 230,   9],\n",
       "        [  2,   0, 103,   2,   4,   0,  43,   6],\n",
       "        [  0,   0,   3,  14,   0,   0,  11,   0],\n",
       "        [  0,  22,   0,   0,   0,   0,   3,   2],\n",
       "        [ 18,   0,   2,   0,   0,   0,   1,   5],\n",
       "        [  1,   0,   4,   0,   1,   0,   6,   1],\n",
       "        [  0,   0,   1,   0,   0,  21,   1,   0],\n",
       "        [  2,   2,   7,   1,   0,   3,  21,  32]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate_on_test(data_folder=data_dir, imgsz=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d9c72",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baeae17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ODIR-2019/results/yolo11n-cls-preprocessed.pt\n",
      "Metadata saved to: ODIR-2019/results/yolo11n-cls-preprocessed_metadata.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('ODIR-2019/results/yolo11n-cls-preprocessed.pt')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Save trained model\n",
    "trainer.save_model(\n",
    "    save_dir='./ODIR-2019/results',\n",
    "    model_name=run_name,\n",
    "    save_format='pt'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
